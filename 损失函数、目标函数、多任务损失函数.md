# 损失函数、目标函数、多任务损失函数

## 损失函数

损失函数（loss function）就是用来度量模型的预测值f(x)与真实值Y的差异程度的运算函数，它是一个非负实值函数，通常使用L(Y, f(x))来表示，损失函数越小，模型的健壮性就越好。

0-1 损失函数
$$
L(Y， f(X)) = \{ \begin{matrix}1, Y\ne f(X) \\ 0,Y= f(X)\end{matrix}
$$
平方损失函数
$$
L(Y， f(X)) = (Y  - f(X))^{2}
$$
绝对损失函数
$$
L(Y， f(X)) = \left | Y  - f(X)) \right | 
$$
对数损失函数
$$
L(Y， P(Y|X)) = -logP(Y|X)
$$

## 目标函数

目标函数f(x)就是用设计变量来表示的所追求的目标形式，所以目标函数就是设计变量的函数，是一个标量。

目标函数是优化问题中的一个概念，在机器学习问题中，通常是在一定约束条件下，以最大/小化这个函数为目标，最终求得对应的参数权重。这个函数就是目标函数。

- 既是损失函数又是目标函数

**最小二乘拟**：给定一组的样本点 $\{(x_{1}, y_{1}),......,(x_{n}, y_{n})\}$ ，我们要求一条直线去拟合这些样本点。假设求出模型形式为$y = \beta ^{T}x $。接着我们要最小化下面这个方程：
$$
argmax_{\beta }\{\sum_{i=0}^{n}(\beta ^{T}x_{i}-y_{i})^{2}\}
$$
上面的这个式子即使损失函数又是目标函数。所以在这个时候，损失函数和目标函数是同一个概念。

- 是目标函数但大于损失函数

  

**脊回归（Ridge regression）**：类似于最小二乘拟合，不过脊回归假设参数足够简单。此时需要对 $\beta$ 做正则化处理。需要优化的函数就变成：
$$
argmax_{\beta }\{\sum_{i=0}^{n}(\beta ^{T}x_{i}-y_{i})^{2} + \lambda \beta ^{T}\beta \}
$$
上式可以称作是目标函数，但却不是损失函数。损失函数仅是这个函数的一部分。

- 是目标函数但没有损失函数

**极大似然估计**：假设我们有一枚硬币，正面的概率是p，反面的概率是（1-p）。将这枚硬币抛了100次后，观察发现有42次正面向上，58次反面向上，求p值？42次正面向上，58次反面向上的概率为 $p^{42}\times(1-p)^{58}$。用极大似然发求p则要优化下面的函数：
$$
argmax_{p}p^{42}\times(1-p)^{58}
$$
在这个例子是仅有目标函数，不存在损失函数。



## 多任务损失函数

让损失函数的值最小是一个模型学习的目标，而反向传播只是优化模型时求梯度（求导）的一种手段。

在多任务中一般是两种方法来定义损失函数：

1、子任务的损失函数直接相加：$L = L_{1} + L _{2}$

2、子任务的损失函数加权相加：$L = \alpha \times L_{1} + \beta \times L_{2} $

第二种方法通常比第一种要好。$L{1}$是任务一的损失，$L_{2}$是任务二的损失。

从梯度是损失函数对参数的求偏导来看，当我们想更新任务一里面的参数时，应该用$L{1}$对参数求偏导最好，但是此时损失函数是$L = L_{1} + L _{2}$不再是$L{1}$ ，求偏导后就引入了$L_{2}$对任务一里面的参数的偏导。这样当然会降低模型的性能，所以我们可以为$L_{1}$和$L_{2}$加权，某种程度来说，这是“降低”一个损失函数对一个不相干的任务在反向传播时的影响。也可以理解为两个任务的梯度有不同的“尺度”，两者的“尺度”差异较大时，一个任务对反向传播时参数更新的影响可能会盖过另外一个任务。

但是采用加权的损失函数$L = \alpha \times L_{1} + \beta \times L_{2} $，参数α 、 β 就变成了需要调整的超参数，它们的设置和任务的“尺度”、学习率、任务的损失大小等等都有些关系，甚至还要去考虑模型泛化的能力。

所以这时提出第三种损失函数，把损失函数前的权重当作是可以学习的参数来学习。